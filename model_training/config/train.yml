---
config:
  name: train # name of the configuration file

basic:
  # The Cuda device ID, that is needed to enable GPU acceleration. Can also be several IDs seperated by Comma
  cuda_device_name: cuda:4
  # The name of the experiment
  experiment_name: AFFFE
  # The description and purpose of the experiment
  experiment_description: Train the AFFFE Network
  # path to save the checkpoints
  result_dir: "/local/scratch/wangy/model_results"
  # path to save preprocessed images
  save_dir: "/local/scratch/wangy/experiments"
  # debug mode
  debug_mode: 0
  # select checkpoint folder 
  checkpoint: Checkpoint_ver_2021-07-14_10-10-04   #resnet51 model



dataset:
  image_dir: "/local/scratch/datasets/VGGFace2"
  # Path to the partition file
  partition_filename: "/local/scratch/wangy/vggface2/datasets/partition.csv"
  # path to train list file
  train_list_labels: "/local/scratch/wangy/vggface2/datasets/train_list_labels.csv"
  # path to test list file
  test_list_labels: "/local/scratch/wangy/vggface2/datasets/test_list_labels.csv"
  # path to the file of validation pairs
  val_pairs: "/local/scratch/wangy/vggface2/datasets/val_pairs_10k.csv"
  # bounding box mode (0 = align with landmarks, 1 = crop with the bounding box file, 2 = crop with a face detector)
  bounding_box_mode: 0
  # Scale the bounding box if bounding box mode 2 is selected
  bounding_box_scale: 2
  # Path to the file which contains the training landmarks information
  loose_landmark_train: "/local/scratch/wangy/vggface2/bb_landmark/loose_landmark_train.csv"
  # Path to the file which contains the test landmarks information
  loose_landmark_test: "/local/scratch/wangy/vggface2/bb_landmark/loose_landmark_test.csv"
  # Path to the training bounding box file
  loose_bb_train: "/local/scratch/wangy/vggface2/bb_landmark/loose_bb_train.csv"
  # Path to the training bounding box file
  loose_bb_test: "/local/scratch/wangy/vggface2/bb_landmark/loose_bb_test.csv"
  # meta file
  meta_file: "/local/scratch/datasets/VGGFace2/identity_meta.csv"

preprocessing:
  # Batch size of training and validation data (training data is split in equal sets of size batch size)
  dataloader:
    # If the data is shuffled before it is split in batches (True for shuffling and False for not shuffling)
    batch_size: 64
    # If the data is shuffled before it is split in batches (True for shuffling and False for not shuffling)
    shuffle: 'True'
    # how many images to preprocess at the same time (>1 uses multiprocessing, suggested around 8 if training on 1 gpu)
    num_workers: 8    #8
    # How many batches are preprocessed on each worker
    prefetch_factor: 10  #10
  save_preprocessed_image:
    # If enabled, saves images in defined frequency
    enabled: 0
    frequency: 10
  transformation:
    crop_size:
      # image gets aligned/cropped and then resized before training
      x: 224
      y: 224
    val_scale: 1
    scale_jitter:
      # Enable scale jitter (0 = disabled, 1 = enabled)
      enabled: 0
      normal_distribution:
        mean: 1.2
        std: 0.1
    angle_jitter:
      # Enable angle jitter (0 = disabled, 1 = enabled)
      enabled: 0
      normal_distribution:
        mean: 0
        std: 20
    shift_jitter:
      # Enable shift jitter (0 = disabled, 1 = enabled)
      enabled: 0
      normal_distribution:
        mean: 0
        std: 0.05
    mirror:
      # Enable mirroring (0 = disabled, 1 = enabled)
      enabled: 0
      probability: 0.5
    gaussian_blur:
      # Enable gaussian blur (0 = disabled, 1 = enabled)
      enabled: 0
      normal_distribution:
        mean: 0
        std: 3
    gamma:
      # Enable gamma (0 = disabled, 1 = enabled)
      enabled: 0
      normal_distribution:
        mean: 0
        std: 1
    temperature:
      # Enable temperature (0 = disabled, 1 = enabled)
      enabled: 0



model:
  # The name of the model
  name: resnet51 #arcface
  # if training.resume=1, set model.pretrained=0
  pretrained: 1
  # The rate of dropout (0.2-0.5 is recommended, only matters if chosen model has a dropout layer)
  feature_size: 512
  # total number of classes in training and test sets is 9131; number of classes in training set is 8631;
  # number of classes for debug is 9
  num_classes: 8631    #9131


training:
  # whether to use parallel computation
  parallel: 0
  # whether to resume a model
  resume: 0
  # How many epochs the model should be trained on
  epochs: 100
  optimizer:
    # Type of Optimizer (e.g. SGD for stochastic gradient descent)
    type: SGD
    # Learning rate (e.g. 0.001, 0.01, 0.1, 1)
    learning_rate: 0.001
    # Momentum
    momentum: 0.9
    # weight decay
    weight_decay: 0.0001
  lr_scheduler:
    # Type of learning rate scheduler that adjusts the Learning rate dynamically during training (e.g. "ReduceLROnPlateau")
    type: ReduceLROnPlateau
    # LRscheduler: after how many epochs the learning rate is adjusted
    step_size: 3
    # multiplicator of learning rate. (e.g. new learning rate = old learning rate * gamma)
    gamma: 0.1
    # How many epochs to wait while the validation loss does not decrease before adjusting the learnig rate
    patience: 2
  early_stop: 8